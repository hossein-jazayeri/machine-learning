# machine-learning

Here are some ML examples implemented by either [python](https://www.python.org/) 
or [octave](https://www.gnu.org/software/octave) during my learnings

Github projects:
- [Machine learning cheat sheet](https://github.com/soulmachine/machine-learning-cheat-sheet)
- [Stanford CoreNLP](https://github.com/stanfordnlp/CoreNLP)
- [T2T: Tensor2Tensor Transformers](https://github.com/tensorflow/tensor2tensor)
- [SfMLearner](https://github.com/tinghuiz/SfMLearner)
- [Programming exercises for the Stanford Unsupervised Feature Learning and Deep Learning Tutorial](https://github.com/amaas/stanford_dl_ex)
[colah's blog](http://colah.github.io/)

Links:
- Andrew Ng's [twitter](https://twitter.com/AndrewYNg) & [website](http://www.andrewng.org/)
- [Master machine learning by using it on real life applications](http://machinelearningmastery.com/)
- [Kaggle](https://www.kaggle.com/)
- [Sebastian Ruder's blog](http://ruder.io/)

Youtube:
- [Lecture 01 - The Learning Problem](https://youtu.be/mbyG85GZ0PI)
- [Deep Learning for Computer Vision (Andrej Karpathy, OpenAI)](https://youtu.be/u6aEYuemt0M)
- [Nuts and Bolts of Applying Deep Learning](https://www.youtube.com/watch?v=F1ka6a13S9I&index=39&list=LLzRZ72F0xgn-WlDkrg8mOhg)

Courses:
- [Machine Learning by Stanford University](https://www.coursera.org/learn/machine-learning/home)
- [Machine Learning Foundations: A Case Study Approach by University of Washington](https://www.coursera.org/learn/ml-foundations/home/welcome)
- [Machine Learning: Regression by University of Washington](https://www.coursera.org/learn/ml-regression/home/welcome)
- [Machine Learning: Classification by University of Washington](https://www.coursera.org/learn/ml-classification/home/welcome)
- [Machine Learning: Clustering & Retrieval by University of Washington](https://www.coursera.org/learn/ml-clustering-and-retrieval/home/welcome)

From [ML Mastery Blog](machinelearningmastery.com)
# Standard machine learning terms
There are key concepts in machine learning that lay the foundation for understanding the field.

I like to break them down into three areas:
- Data
- Learning
- Modeling

 You need to know about data, such as a data instance, data feature and datasets like test and training datasets.

Learning is a big topic. Induction is the main type of learning used by machine learning algorithms 
(this is generalizing from specific examples). With generalizing there is the risk of over-learning (too specific) 
and under-learning (too general). 

Then there is the type of learning, such as online or offline (real-time or batch) and supervised or unsupervised 
(teacher or no teacher).

The model is the artifact created from running an algorithm. It is the "thing" that you can use to describe the structure 
in the data or make predictions from new data. 

There are two big issues when it comes to the model and that is the bias (the assumptions made to create the model) 
and the variance (how sensitive it is to data). You may have heard of the bias-variance trade-off that seeks a balance 
between these two concerns.
 
Learn more about the standard machine learning terms in the post:
- [Data, Learning and Modeling](http://machinelearningmastery.com/data-learning-and-modeling/)
